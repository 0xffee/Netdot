#
# Check for existing max IDs for tables 
# such as physaddr, ipblock (these have high churn rates)
# and, if necessary, renumber all the existing records' fields starting from 1.
# This script also updates any foreign key fields referencing these IDs.
# 
# We do not attempt to update anything related to
# fwtable, fwtableentry, arpcache, or arpcacheentry
# since they are usually time-consuming and can be solve easily by
# executing prune_db.pl, such as bin/prune_db.pl -F -A -d 7 -r
# 
use strict;
use lib "../lib";
use DBUTIL;
use Netdot;
use Netdot::Model;
use Data::Dumper;

my %CONFIG;
$CONFIG{debug}             = 0;
$CONFIG{threshold}         = 0.01;

my $real_run = 1;

my $mysql_uint_max = 4294967295;
my $pg_uint_max    = 2147483647;

foreach my $var ( qw /DB_TYPE DB_HOME DB_HOST DB_PORT DB_DBA DB_DBA_PASSWORD 
		  DB_NETDOT_USER DB_NETDOT_PASS DB_DATABASE/ ){
    $CONFIG{$var} = Netdot->config->get($var);
}

# need DBA's ALTER privileges, which netdot_user does not have
my $dbh = &dbconnect($CONFIG{DB_TYPE}, $CONFIG{DB_HOST}, $CONFIG{DB_PORT}, 
		     $CONFIG{DB_DBA}, $CONFIG{DB_DBA_PASSWORD}, $CONFIG{DB_DATABASE});

my @tables = Netdot->meta->get_tables(with_history=>0);

if ( $CONFIG{DB_TYPE} eq 'mysql' ){
    foreach my $t ( @tables ){
	my %locks = ();
	my $table = lc($t->db_name);
	my ($max_id) = $dbh->selectrow_array("SELECT max(id) FROM $table");
	$max_id = 0 if !defined($max_id);
	next if 1.0*$max_id / $mysql_uint_max < $CONFIG{threshold};
	
	my ($count_id) = $dbh->selectrow_array("SELECT count(id) FROM $table");
	print "Defragmenting table $table (max ID is $max_id, number of IDs is $count_id)...\n";
	
	# finding which tables to lock (WRITE lock)
	$locks{$table} = 1;
	my %from = $t->get_links_from;
	foreach my $method ( keys %from ){
	    foreach my $far_table ( keys %{ $from{$method} } ){
		my $far_tname = $far_table->meta_data->db_name;
		if ( !exists $locks{$far_tname} ) {
		    $locks{$far_tname} = 1;
		}
	    }
	}
	
	# check if {fwtable, fwtableentry, arpcache, arpcacheentry} is to be updated
	my $skip = 0;
	foreach my $big_table ( qw /arpcache arpcacheentry fwtable fwtableentry/ ) {
	    if ( exists $locks{$big_table} ) {
		my ($ref_count) = $dbh->selectrow_array("SELECT count(id) FROM $big_table");
		if ( $ref_count > 0 ) {
		    $skip = 1;
		    last;
		}
	    }
	}
	if ($skip == 1) {
	    print "Skipping table $table because it references to a large table (it may be too time consuming to update).\n";
	    print "Please run prune_db.pl with rotate on arpcache, arpcacheentry, fwtable, fwtableentry first.\n";
	    next;
	}
	
	# before locking tables, check if we need to do transactions
	# i.e. we need transactions if this table is referenced by other tables
	# mysql suggests to use "SET autocommit=0" rather than "START TRANSACTION"
	if ( (scalar keys %from) > 0 ){
	    $dbh->{AutoCommit} = 0 if $real_run;
	}
	
	# actually locking the tables
	my $lock_st = "LOCK TABLES " . join(', ', keys %locks) . " WRITE";
	$lock_st =~ s/,/ WRITE,/g;
	$dbh->do($lock_st) if $real_run;
	print $lock_st."\n" if $CONFIG{debug};
	
	# prepare statements
	my $smallest_id_st = $dbh->prepare("SELECT min(id) FROM $table WHERE id>?");
	my $update_id_st   = $dbh->prepare("UPDATE $table SET id=? WHERE id=?");
	my %update_st = ();
	foreach my $method ( keys %from ){
	    foreach my $far_table ( keys %{ $from{$method} } ){
		my $far_tname = $far_table->meta_data->db_name;
		my $far_col = $from{$method}{$far_table};
		$update_st{$far_tname} = $dbh->prepare("UPDATE $far_tname SET $far_col=? WHERE $far_col=?");
	    }
	}
	
	# shift down the ids so that they start from 1
	my $new_index = 1;
	my @new_id_st = ();
	my $prev_id = 0;
	my $old_id = 0;
	for ( $new_index = 1; ; $new_index++ ) {
	    $smallest_id_st->execute($old_id);
	    ($old_id) = $smallest_id_st->fetchrow_array();
	    last if !defined($old_id);
	    last if $old_id == $prev_id;
	    next if $old_id == $new_index;
	    
	    $update_id_st->execute($new_index,$old_id) if $real_run;
	    print "UPDATE $table SET id=$new_index WHERE id=$old_id"."\n" if $CONFIG{debug};
	    
	    # get the other tables that link to this id
	    # and update those values
	    foreach my $far_tname ( keys %update_st ) {
		$update_st{$far_tname}->execute($new_index,$old_id);
	    }
	    $prev_id = $old_id;
	    
	    if ( (scalar keys %from) > 0 ){
		$dbh->commit if $real_run;
	    }
	}
	
	$dbh->do("ALTER TABLE $table AUTO_INCREMENT=$new_index") if $real_run;
	print "ALTER TABLE $table AUTO_INCREMENT=$new_index"."\n" if $CONFIG{debug};
	
	# unlock the tables
	$dbh->commit if $real_run;
	$dbh->do("UNLOCK TABLES") if $real_run;
	
	# set autocommit back to 1
	$dbh->{AutoCommit} = 1 if $real_run;
	
	my ($new_max_id) = $dbh->selectrow_array("SELECT max(id) FROM $table");
	print "Done with $table, new max ID is $new_max_id.\n";
	
	print $table.": ".1.0*$max_id/$mysql_uint_max."\n\n" if $CONFIG{debug};
    }
} elsif ( $CONFIG{DB_TYPE} =~ /^pg$/i ) {
    # The only two things that are different is table locking
    # and modifying the auto increment index.
    # 
    # For the table locking part, 
    # the idea is to write (exclusive) lock the table so that the new value of auto_increment at the end is valid (nobody can generate a new id during this update)
    # make sure transactions (AutoCommit set to 0) play well with locks (although the use of AutoCommit = 0 rather than explicit transactions should be ok for Pg as well)
    # 
    # For the auto increment part, the SQL query is:
    # $dbh->do("SELECT setval('" . $table . "_id_seq', $new_index, false)"); #nextval() will return new_index
    print "Pg currently not supported.\n";
} else {
    print "Database type $CONFIG{db_type} is not supported.\n";
}

&dbdisconnect($dbh);

sub debug {
    print STDERR "[DEBUG] Executing: ", @_, "\n" if $CONFIG{debug};
}
